This folder shows three experiments from our latest research paper, "Evaluation of ChatGPT's Smart Contract Auditing Capabilities Based on Chain of Thought" which are:

Experiment 1-Solidyfi-benchmark vulnerability detection capability test; 

Experiment 2 - Code detection based on smart contract audit reports; 

Experiment 3 - Writing the POC;

Our study explores the potential of enhancing smart contract security audits using the GPT-4 model. We utilized a dataset of 35 smart contracts from the SolidiFI-benchmark vulnerability library, containing 732 vulnerabilities, and compared it with five other vulnerability detection tools to evaluate GPT-4's ability to identify seven common types of vulnerabilities. Moreover, we assessed GPT-4's performance in code parsing and vulnerability capture by simulating a professional auditor's auditing process using Chain of Thought (CoT) prompts based on the audit reports of eight groups of smart contracts. We also evaluated GPT-4's ability to write Solidity Proof of Concepts (PoCs).

In order to facilitate the research of scholars, our experimental results are open to you. If you are interested, please contact us.
